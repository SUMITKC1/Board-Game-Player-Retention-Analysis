{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Modeling Notebook\n",
    "\n",
    "This notebook performs:\n",
    "- EDA (activity trends, retention curves)\n",
    "- Feature engineering (avg session length, recency, purchases, level progression)\n",
    "- Modeling (Logistic Regression, Random Forest, XGBoost)\n",
    "- Evaluation (Accuracy, ROC-AUC), feature importance\n",
    "- Save best model to `models/churn_xgb.pkl`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and setup\n",
    "import os, sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Ensure project root on path\n",
    "root = os.path.abspath(os.getcwd())\n",
    "if root not in sys.path:\n",
    "    sys.path.insert(0, root)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from src.preprocess import load_data, create_features\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "DATA_DIR = 'data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data and create features\n",
    "raw = load_data(DATA_DIR)\n",
    "train_df, dev_df, test_df = create_features(raw)\n",
    "\n",
    "print('train/dev/test shapes:', train_df.shape, dev_df.shape, test_df.shape)\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA: churn distribution and retention proxy\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "if 'churn' in train_df.columns:\n",
    "    train_df['churn'].value_counts(normalize=True).plot(kind='bar', ax=ax[0], title='Churn Rate')\n",
    "else:\n",
    "    # try common alt label column\n",
    "    alt = 'label' if 'label' in train_df.columns else None\n",
    "    if alt:\n",
    "        train_df[alt].value_counts(normalize=True).plot(kind='bar', ax=ax[0], title=f'{alt} Rate')\n",
    "    else:\n",
    "        ax[0].set_title('No churn/label column found')\n",
    "\n",
    "if 'recency_days' in train_df.columns and train_df['recency_days'].notna().any():\n",
    "    train_df['recency_days'].plot(kind='hist', bins=30, ax=ax[1], title='Recency (days)')\n",
    "else:\n",
    "    if 'purchase_count' in train_df.columns:\n",
    "        train_df['purchase_count'].plot(kind='hist', bins=30, ax=ax[1], title='Purchase Count')\n",
    "    else:\n",
    "        ax[1].set_title('No recency/purchase features')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Retention proxy\n",
    "if 'recency_days' in train_df.columns and 'label' in train_df.columns:\n",
    "    tmp = train_df[['recency_days', 'label']].dropna().sort_values('recency_days')\n",
    "    if not tmp.empty:\n",
    "        tmp['active'] = 1 - tmp['label']\n",
    "        tmp['cum_active_rate'] = tmp['active'].expanding().mean()\n",
    "        tmp[['recency_days','cum_active_rate']].plot(x='recency_days', y='cum_active_rate', figsize=(6,4), title='Retention proxy by recency')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare modeling data with robust coercion\n",
    "\n",
    "def prepare_xy(df, label_col='churn'):\n",
    "    if label_col not in df.columns:\n",
    "        for alt in ['is_churn','label','target']:\n",
    "            if alt in df.columns:\n",
    "                label_col = alt\n",
    "                break\n",
    "    y = df[label_col].values if label_col in df.columns else None\n",
    "    feat_cols = [c for c in df.columns if c not in {label_col, 'player_id'}]\n",
    "    Xdf = df[feat_cols].copy()\n",
    "    for c in Xdf.columns:\n",
    "        Xdf[c] = pd.to_numeric(Xdf[c], errors='coerce')\n",
    "    Xdf = Xdf.fillna(0.0)\n",
    "    return Xdf.values.astype('float32'), y, feat_cols\n",
    "\n",
    "X, y, feature_cols = prepare_xy(train_df)\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train models and evaluate\n",
    "models = {\n",
    "    'logreg': LogisticRegression(max_iter=1000),\n",
    "    'rf': RandomForestClassifier(n_estimators=300, random_state=42, n_jobs=-1),\n",
    "    'xgb': XGBClassifier(n_estimators=300, max_depth=5, learning_rate=0.08, subsample=0.9,\n",
    "                         colsample_bytree=0.9, reg_lambda=1.0, objective='binary:logistic',\n",
    "                         eval_metric='auc', random_state=42, n_jobs=-1, tree_method='hist'),\n",
    "}\n",
    "\n",
    "metrics = {}\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    pred = clf.predict(X_va)\n",
    "    proba = clf.predict_proba(X_va)[:,1]\n",
    "    acc = accuracy_score(y_va, pred)\n",
    "    auc = roc_auc_score(y_va, proba)\n",
    "    metrics[name] = {'accuracy': acc, 'roc_auc': auc}\n",
    "    print(f\"{name}: acc={acc:.4f}, auc={auc:.4f}\")\n",
    "\n",
    "best_name = max(metrics.keys(), key=lambda k: metrics[k]['roc_auc'])\n",
    "print('Best model:', best_name, metrics[best_name])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance for XGB\n",
    "if 'xgb' in models:\n",
    "    xgb = models['xgb']\n",
    "    importances = xgb.feature_importances_\n",
    "    fi = pd.DataFrame({'feature': feature_cols, 'importance': importances}).sort_values('importance', ascending=False)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.barplot(data=fi.head(20), x='importance', y='feature')\n",
    "    plt.title('Top 20 Feature Importances (XGB)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model\n",
    "import joblib, os\n",
    "best_clf = models[best_name]\n",
    "os.makedirs('../models', exist_ok=True)\n",
    "joblib.dump({'model': best_clf, 'features': feature_cols}, '../models/churn_xgb.pkl')\n",
    "print('Saved model to ../models/churn_xgb.pkl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Churn Modeling Notebook\n",
    "\n",
    "This notebook performs:\n",
    "- EDA (activity trends, retention curves)\n",
    "- Feature engineering (avg session length, recency, purchases, level progression)\n",
    "- Modeling (Logistic Regression, Random Forest, XGBoost)\n",
    "- Evaluation (Accuracy, ROC-AUC), feature importance\n",
    "- Save best model to `models/churn_xgb.pkl`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m accuracy_score, roc_auc_score, roc_curve\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxgboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m XGBClassifier\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocess\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_data, create_features\n\u001b[32m     16\u001b[39m get_ipython().run_line_magic(\u001b[33m'\u001b[39m\u001b[33mmatplotlib\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33minline\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     17\u001b[39m sns.set(style=\u001b[33m'\u001b[39m\u001b[33mwhitegrid\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "# Imports and setup\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from src.preprocess import load_data, create_features\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style='whitegrid')\n",
    "\n",
    "DATA_DIR = 'data'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw data and create features\n",
    "raw = load_data(DATA_DIR)\n",
    "train_df, dev_df, test_df = create_features(raw)\n",
    "\n",
    "# Peek\n",
    "display(train_df.head())\n",
    "print(train_df.shape, dev_df.shape, test_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDA: retention curve (toy version)\n",
    "# Expect columns: player_id, churn (1=churned), and optionally last_active or last_login timestamps\n",
    "eda_df = train_df.copy()\n",
    "\n",
    "# Distribution of churn\n",
    "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
    "eda_df['churn'].value_counts(normalize=True).plot(kind='bar', ax=ax[0], title='Churn Rate')\n",
    "ax[0].set_xticklabels(['Active(0)','Churn(1)'], rotation=0)\n",
    "\n",
    "# Activity trend: simple histogram of recency if present\n",
    "if 'recency_days' in eda_df.columns:\n",
    "    eda_df['recency_days'].plot(kind='hist', bins=30, ax=ax[1], title='Recency (days)')\n",
    "else:\n",
    "    eda_df['purchase_count'].plot(kind='hist', bins=30, ax=ax[1], title='Purchase count distribution')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Retention-like curve proxy: cumulative fraction of active by recency\n",
    "if 'recency_days' in eda_df.columns:\n",
    "    tmp = eda_df[['recency_days','churn']].dropna().sort_values('recency_days')\n",
    "    tmp['active'] = 1 - tmp['churn']\n",
    "    tmp['cum_active_rate'] = tmp['active'].expanding().mean()\n",
    "    tmp[['recency_days','cum_active_rate']].plot(x='recency_days', y='cum_active_rate', figsize=(6,4), title='Retention proxy by recency')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare modeling data\n",
    "\n",
    "def prepare_xy(df, label_col='churn'):\n",
    "    if label_col not in df.columns:\n",
    "        for alt in ['is_churn','label','target']:\n",
    "            if alt in df.columns:\n",
    "                label_col = alt\n",
    "                break\n",
    "    y = df[label_col].values if label_col in df.columns else None\n",
    "    feature_cols = [c for c in df.columns if c not in {label_col, 'player_id'}]\n",
    "    X = df[feature_cols].values\n",
    "    return X, y, feature_cols\n",
    "\n",
    "X, y, feature_cols = prepare_xy(train_df)\n",
    "X_tr, X_va, y_tr, y_va = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline models\n",
    "models = {\n",
    "    'logreg': LogisticRegression(max_iter=1000, n_jobs=None),\n",
    "    'rf': RandomForestClassifier(n_estimators=300, max_depth=None, n_jobs=-1, random_state=42),\n",
    "    'xgb': XGBClassifier(n_estimators=300, max_depth=5, learning_rate=0.08, subsample=0.9,\n",
    "                         colsample_bytree=0.9, reg_lambda=1.0, objective='binary:logistic',\n",
    "                         eval_metric='auc', random_state=42, n_jobs=-1, tree_method='hist'),\n",
    "}\n",
    "\n",
    "metrics = {}\n",
    "for name, clf in models.items():\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    pred = clf.predict(X_va)\n",
    "    proba = clf.predict_proba(X_va)[:,1]\n",
    "    acc = accuracy_score(y_va, pred)\n",
    "    auc = roc_auc_score(y_va, proba)\n",
    "    metrics[name] = {'accuracy': acc, 'roc_auc': auc}\n",
    "    print(f\"{name}: acc={acc:.4f}, auc={auc:.4f}\")\n",
    "\n",
    "best_name = max(metrics.keys(), key=lambda k: metrics[k]['roc_auc'])\n",
    "print('Best model:', best_name, metrics[best_name])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (XGBoost)\n",
    "if 'xgb' in models:\n",
    "    xgb = models['xgb']\n",
    "    importances = xgb.feature_importances_\n",
    "    fi = pd.DataFrame({'feature': feature_cols, 'importance': importances}).sort_values('importance', ascending=False)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.barplot(data=fi.head(20), x='importance', y='feature')\n",
    "    plt.title('Top 20 Feature Importances (XGB)')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save best model as models/churn_xgb.pkl (prefer XGB if best)\n",
    "import joblib, os\n",
    "best_clf = models[best_name]\n",
    "os.makedirs('models', exist_ok=True)\n",
    "joblib.dump({'model': best_clf, 'features': feature_cols}, 'models/churn_xgb.pkl')\n",
    "print('Saved model to models/churn_xgb.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
